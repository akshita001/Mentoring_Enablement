## Data Science Interview and Evaluation checklist
I wish to follow some of below points and look for those attributes in candidates for intake into my teams. Of course, these are not exhaustive and they do change as we progress and considering ever changing needs. Another key aspect is the "specific" need. The "Job Description" can never be generic and we should not include "all" or everything under the hood if we are not clear what attributes we are looking for. It may be a good practice to include - "desired background/academia", "number of years of experiential skills or project skills", "whether role focuses on Data Visualization, Data Journalism, Data Engineering, Machine Learning, Deep Learning, ML/DL management and operationalization or so", "what is mandatory or MUST HAVE", "what is NICE to HAVE and optional" and so on..

As an interviewer, one should very carefully follow below criteria and points in a Data Scientist role

- **1. Core background**
- [ ] Profile Background - better to have Bachelors in Comp Sc, Masters in Comp Sc/Stats/Maths/Analytics or equivalent, PhD is great in similar space, but PhD is not mandatory.
- [ ] Learning proof + Experiential proof

- **2. Base Skills**
- [ ] Math and Stats knowledge
- [ ] Story telling ability, Data Journalist skills
- [ ] Communication, articulation ability
- [ ] Thinking of a problem first rather delving into solutions
- [ ] Ability to think of multiple approaches / methods to a problem
- [ ] Core Machine Learning, Deep Learning skills depending on experience level
- [ ] Design thinking thoughts

- **3. Practical Skills**
- [ ] Methodology 
  - CRISP-DM
  - End to end Data Science approach
- [ ] Business understanding
  - Goals / Objectives
  - Business KPIs, Drivers
- [ ] EDA
  - Understand data type - numeric, categorical, 
  - Missing values
  - Outliers
  - Correlation
  - Scatter plots, Box plots etc
  - Data transformation, One hot encoding etc., Log transformation
- [ ] Feature Engineering, Data Preparation
  - Feature selection
  - Cross validation
  - Grid search
- [ ] Programming Knowledge in Open sources such as Python and R
  - Libraries
  - GitHub examples
  - Challenging scenarios
- [ ] Model development
  - Models / Algorithms to select based on Classification, Clustering, Regression, Forecasting, Neural Net etc
- [ ] Model evaluation
  - ROC, AUC
  - Confusion Matrix
  - Precision, Recall
  - KS chart
  - Others
- [ ] Deployment
  - Architecture
  - Microservices
- [ ] Lessons Learnt
  - Stakeholder management experience
  - Data Quality experience
  - Feature importance
  - Explaining what could go better NEXT
- [ ] Model Interpretability
  - Understanding model details 
  - Bias, Variance
  - Fairness
  - Ethics, Trust
- [ ] Forum exposure, Staying current, Though Leadership
  - Blogs
  - Disclosures
  - Papers/Publications
